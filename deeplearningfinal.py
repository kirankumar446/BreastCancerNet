# -*- coding: utf-8 -*-
"""DeepLearningFINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O1AAIPvjmRnvNH7119LAMnLTESpnN4YO

#Drive Mount: Establishing Data Accessibility
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""#Required Libraries:"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import pydot
import seaborn as sns
from keras import models
from keras.layers import Dense, Conv1D, Attention, Flatten, Dropout, LSTM
from keras.models import Sequential,Model
from keras import utils
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.preprocessing import LabelEncoder
!pip install sklearn
!pip install tensorflow
import sklearn
from sklearn.metrics import roc_curve, auc
from keras.callbacks import EarlyStopping
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import History
from sklearn.metrics import roc_auc_score

"""#Data reading:"""

df = pd.read_csv('/content/gdrive/MyDrive/Dataset/Breastcancer.csv')

from google.colab import drive
drive.mount('/content/drive')

B,M = df['diagnosis'].value_counts()
print(f"Benign = {B}, Malignant = {M}")

plt.rcParams['figure.figsize'] = (8,5)
sns.countplot(x="diagnosis", data=df)
plt.subplot().set_xticklabels(["Malignant", "Benign"])

df.drop(columns='id', inplace=True)

"""# Data preprocessing:"""

y=df.diagnosis
X = df.drop(['diagnosis'], axis=1)

df.columns.isnull()

df.describe()

df.describe()

diagnosis_y = LabelEncoder()
df['diagnosis'] = diagnosis_y.fit_transform(df['diagnosis'])

"""#Train Test Split:"""

data = load_breast_cancer()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(X)
X = scaler.transform(X)

# Normalize the data using the MinMaxScaler.
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#Model Creation:"""

model = Sequential()
model.add(Dense(64, input_dim=30, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

"""#Model Training:"""

# Train the model and obtain the history object
history = History()
model.fit(X_train, y_train, epochs=150, validation_data=(X_test, y_test), callbacks=[history])

#Calculate binary predictions on the test set
y_pred_probs = model.predict(X_test)
y_pred = (y_pred_probs > 0.5).astype(int).reshape(-1,)

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)

# Calculate accuracy on the test set
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy Score = ', accuracy)

loss, accuracy = model.evaluate(X_test, y_test)

print(f'Loss in the ANN Model design : {loss:.4f}')
print(f'Accuracy in the ANN Model design : {accuracy*100:.4f}')

"""#Graphs:"""

history = globals()['history']
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Convergence Plot')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plotting training and validation accuracy
plt.figure(figsize=(14, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
#plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plotting training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
#plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))

# Plotting training and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')

# Plotting training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')

#plt.title('Performance curve of the proposed method')
plt.xlabel('No of epochs')
plt.ylabel('Accuracy/Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""#Confusion Matrix:"""

cm = confusion_matrix(y_test,y_pred)

cm

plt.figure(figsize=(7,5))
plt.rcParams.update({'font.size': 16})
sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', cbar=True,
                xticklabels=['Benign', 'Malignant'],
                yticklabels=['Benign', 'Malignant'])
plt.title("Confusion Matrix")
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')

"""#ROC curves:"""

# Compute ROC Curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
roc_auc = roc_auc_score(y_test, y_pred_probs)
plt.figure(figsize=(8,6))
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
plt.plot(fpr, tpr, color='darkorange', label='HyBCNet (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
#plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()