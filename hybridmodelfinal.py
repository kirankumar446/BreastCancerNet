# -*- coding: utf-8 -*-
"""HybridModelFINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j-v5pOYWsVh07WFTCURGqVEpjWfUds2p

## **Drive Mount**
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""## **Required libraries**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score, confusion_matrix
#from keras_self_attention import SeqSelfAttention
from keras import models
from keras.layers import Dense, Conv1D, Attention, Flatten, Dropout, LSTM
from keras.models import Sequential,Model
from keras import utils
import tensorflow as tf
import pydot
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.preprocessing import LabelEncoder
from keras.callbacks import EarlyStopping
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
!pip install sklearn
import sklearn
!pip install tenserflow
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import History
from tensorflow.keras.utils import plot_model

"""# Data Reading"""

df = pd.read_csv('/content/gdrive/MyDrive/Dataset/Breastcancer.csv')
df.head(10)

df.columns.isnull()

df.describe()

B,M = df['diagnosis'].value_counts()
print(f"Benign = {B}, Malignant = {M}")

plt.rcParams['figure.figsize'] = (8,5)
sns.countplot(x="diagnosis", data=df)
plt.subplot().set_xticklabels(["Malignant", "Benign"])

df.shape

"""# Data Preprocessing"""

y=df.diagnosis
X = df.drop(['diagnosis'], axis=1)

df

data = load_breast_cancer()
X = data.data
y = data.target

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(X)
X = scaler.transform(X)

diagnosis_y = LabelEncoder()
df['diagnosis'] = diagnosis_y.fit_transform(df['diagnosis'])

print(df.isnull().sum())

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# Fit the scaler to the data
scaler.fit(X)

# Transform the data using the fitted scaler
x_standardized = pd.DataFrame(scaler.transform(X), columns=data.feature_names)

x_standardized

"""# Train Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data using the MinMaxScaler.
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Model creation"""

# Create a Sequential model
model = Sequential()

# Add Dense layers with ReLU activation and Dropout
model.add(Dense(units=3, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(units=3, activation='relu'))
model.add(Dropout(0.25))

# Add more Dense layers as needed
model.add(Dense(units=3, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(units=3, activation='sigmoid'))
model.add(Dropout(0.25))

# Create an instance of the SVC class
svm_classifier = SVC(kernel='linear', C=1.0)

# Add a Dense layer with linear activation as the last hidden layer for feature extraction
model.add(Dense(units=128, activation='linear', name='svm_feature_extraction'))

# Add the SVM layer
model.add(Dense(units=1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])

# Assuming you have X_train and y_train
# Train the model
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Extract features using the trained model
feature_extraction_model = Sequential(model.layers[:-1])  # Exclude the output layer
features = feature_extraction_model.predict(X_train)

# Standardize the features
scaler = StandardScaler()
features_standardized = scaler.fit_transform(features)

# Fit the SVM classifier on the standardized features
svm_classifier.fit(features_standardized, y_train)

# Make predictions using the trained SVM model
svm_predictions = svm_classifier.predict(scaler.transform(feature_extraction_model.predict(X_test)))

# Evaluate the SVM model
svm_accuracy = accuracy_score(y_test, svm_predictions)
print(f"SVM Accuracy: {svm_accuracy}")

from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline

# Create a pipeline with feature extraction and SVM classifier
pipeline = make_pipeline(StandardScaler(), svm_classifier)

# Perform cross-validation
cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')

# Print cross-validation scores
print("Cross-Validation Scores:", cv_scores)
print("Mean Accuracy:", cv_scores.mean())

# Print the model summary
model.summary()

# Optionally, you can also plot the model architecture
plot_model(model, show_shapes=True)

from keras.utils import plot_model
plot_model(model, to_file='model.png')

"""# Confusion Matrix:"""

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, svm_predictions)
# Create a Pandas DataFrame from the confusion matrix
conf_matrix_df = pd.DataFrame(conf_matrix,
                                index=['Benign', 'Malignant'],
                                  columns=['Benign', 'Malignant'])

# Print the numerical values
print(conf_matrix_df)

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=['Benign', 'Malignant'],
                yticklabels=['Benign', 'Malignant'])
plt.title(f'Confusion Matrix for Hybrid model')
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.show()

"""#ROC curves:"""

# Plot ROC curve
fpr, tpr, _ = roc_curve(y_test, svm_predictions)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()